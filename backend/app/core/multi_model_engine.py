"""
å¤šæ¨¡å‹æ¨ç†å¼•æ“ - æ”¯æŒå¤šä¸ªAPIæä¾›å•†
"""

from typing import Optional, Dict, Any, List, Iterator, Union
from loguru import logger
import httpx
import json
from app.core.config import settings


class MultiModelEngine:
    """æ”¯æŒå¤šç§æ¨¡å‹æä¾›å•†çš„æ¨ç†å¼•æ“"""
    
    PROVIDERS = {
        "openai": {
            "name": "OpenAI",
            "base_url": "https://api.openai.com/v1",
            "default_model": "gpt-4-turbo-preview",
            "models": []  # å°†é€šè¿‡APIåŠ¨æ€è·å–
        },
        "openrouter": {
            "name": "OpenRouter",
            "base_url": "https://openrouter.ai/api/v1",
            "default_model": "anthropic/claude-3-opus",
            "models": []  # å°†é€šè¿‡APIåŠ¨æ€è·å–
        },
        "gemini": {
            "name": "Google Gemini",
            "base_url": "https://generativelanguage.googleapis.com/v1beta",
            "default_model": "gemini-pro",
            "models": []  # å°†é€šè¿‡APIåŠ¨æ€è·å–
        },
        "anthropic": {
            "name": "Anthropic Claude",
            "base_url": "https://api.anthropic.com/v1",
            "default_model": "claude-3-opus-20240229",
            "models": []  # å°†é€šè¿‡APIåŠ¨æ€è·å–
        },
        "deepseek": {
            "name": "DeepSeek",
            "base_url": "https://api.deepseek.com/v1",
            "default_model": "deepseek-chat",
            "models": []  # å°†é€šè¿‡APIåŠ¨æ€è·å–
        },
        "qwen": {
            "name": "Qwen (é€šä¹‰åƒé—®)",
            "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
            "default_model": "qwen-turbo",
            "models": []  # å°†é€šè¿‡APIåŠ¨æ€è·å–
        },
        "local": {
            "name": "æœ¬åœ°æ¨¡å‹",
            "base_url": "http://localhost:8001/v1",
            "default_model": "local-model",
            "models": []  # å°†é€šè¿‡APIåŠ¨æ€è·å–
        }
    }
    
    def __init__(self):
        self.api_keys: Dict[str, str] = {}
        self.custom_configs: Dict[str, Dict[str, Any]] = {}
        self.available_models: Dict[str, List[str]] = {}  # å­˜å‚¨æ¯ä¸ªæä¾›å•†çš„å¯ç”¨æ¨¡å‹
    
    def set_api_key(self, provider: str, api_key: str):
        """è®¾ç½®APIå¯†é’¥"""
        self.api_keys[provider] = api_key
        logger.info(f"å·²è®¾ç½® {provider} APIå¯†é’¥")
    
    def set_custom_config(self, provider: str, config: Dict[str, Any]):
        """è®¾ç½®è‡ªå®šä¹‰é…ç½®"""
        self.custom_configs[provider] = config
        logger.info(f"å·²è®¾ç½® {provider} è‡ªå®šä¹‰é…ç½®")
    
    def set_available_models(self, provider: str, models: List[str]):
        """è®¾ç½®æä¾›å•†çš„å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        self.available_models[provider] = models
        logger.info(f"å·²è®¾ç½® {provider} å¯ç”¨æ¨¡å‹: {len(models)} ä¸ª")
    
    async def verify_api_key(self, provider: str, api_key: str, base_url: Optional[str] = None) -> Dict[str, Any]:
        """
        éªŒè¯APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ
        
        Returns:
            {
                "valid": bool,
                "message": str,
                "models": List[str]  # å¦‚æœæˆåŠŸï¼Œè¿”å›å¯ç”¨æ¨¡å‹åˆ—è¡¨
            }
        """
        provider_info = self.PROVIDERS.get(provider, {})
        test_base_url = base_url or provider_info.get("base_url", "")
        
        logger.info(f"ğŸ” å¼€å§‹éªŒè¯ {provider} APIå¯†é’¥...")
        logger.info(f"   Base URL: {test_base_url}")
        logger.info(f"   API Keyå‰ç¼€: {api_key[:10]}..." if api_key else "   API Key: æœªæä¾›")
        
        try:
            # å°è¯•è·å–æ¨¡å‹åˆ—è¡¨
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            # å¢åŠ è¶…æ—¶æ—¶é—´ï¼Œæ”¯æŒä»£ç†
            async with httpx.AsyncClient(timeout=60.0, follow_redirects=True) as client:
                # å¯¹äºOpenAIå…¼å®¹çš„APIï¼Œå°è¯•è·å–æ¨¡å‹åˆ—è¡¨
                if provider in ["openai", "openrouter", "deepseek", "qwen", "local"]:
                    try:
                        logger.info(f"   å°è¯•è·å–æ¨¡å‹åˆ—è¡¨: {test_base_url}/models")
                        response = await client.get(
                            f"{test_base_url}/models",
                            headers=headers
                        )
                        logger.info(f"   å“åº”çŠ¶æ€ç : {response.status_code}")
                        
                        if response.status_code == 200:
                            data = response.json()
                            models = [m.get("id") or m.get("name") for m in data.get("data", [])]
                            logger.info(f"   âœ… æˆåŠŸè·å– {len(models)} ä¸ªæ¨¡å‹")
                            return {
                                "valid": True,
                                "message": "APIå¯†é’¥éªŒè¯æˆåŠŸ",
                                "models": models if models else []
                            }
                        else:
                            logger.warning(f"   è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {response.status_code} - {response.text[:200]}")
                    except Exception as e:
                        logger.warning(f"   è·å–æ¨¡å‹åˆ—è¡¨å¼‚å¸¸: {str(e)}")
                
                # å¦‚æœè·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥ï¼Œå°è¯•ç®€å•çš„èŠå¤©è¯·æ±‚
                logger.info(f"   å°è¯•å¤‡ç”¨éªŒè¯æ–¹å¼: å‘é€æµ‹è¯•è¯·æ±‚")
                test_payload = {
                    "model": provider_info.get("default_model", "gpt-3.5-turbo"),
                    "messages": [{"role": "user", "content": "hi"}],
                    "max_tokens": 5
                }
                
                if provider == "gemini":
                    # Geminiç‰¹æ®Šå¤„ç†
                    url = f"{test_base_url}/models/gemini-pro:generateContent?key={api_key}"
                    test_payload = {
                        "contents": [{"role": "user", "parts": [{"text": "hi"}]}]
                    }
                    logger.info(f"   Geminiè¯·æ±‚URL: {url}")
                    response = await client.post(url, json=test_payload)
                elif provider == "anthropic":
                    # Claudeç‰¹æ®Šå¤„ç†
                    headers["x-api-key"] = api_key
                    headers["anthropic-version"] = "2023-06-01"
                    del headers["Authorization"]
                    test_payload = {
                        "model": "claude-3-haiku-20240307",
                        "messages": [{"role": "user", "content": "hi"}],
                        "max_tokens": 5
                    }
                    logger.info(f"   Claudeè¯·æ±‚URL: {test_base_url}/messages")
                    response = await client.post(
                        f"{test_base_url}/messages",
                        headers=headers,
                        json=test_payload
                    )
                else:
                    # OpenAIå…¼å®¹æ ¼å¼
                    url = f"{test_base_url}/chat/completions"
                    logger.info(f"   è¯·æ±‚URL: {url}")
                    response = await client.post(
                        url,
                        headers=headers,
                        json=test_payload
                    )
                
                logger.info(f"   æµ‹è¯•è¯·æ±‚å“åº”çŠ¶æ€ç : {response.status_code}")
                
                if response.status_code in [200, 201]:
                    logger.info(f"   âœ… æµ‹è¯•è¯·æ±‚æˆåŠŸ")
                    return {
                        "valid": True,
                        "message": "APIå¯†é’¥éªŒè¯æˆåŠŸï¼ˆé€šè¿‡æµ‹è¯•è¯·æ±‚ï¼‰",
                        "models": []  # æ¨¡å‹åˆ—è¡¨è·å–å¤±è´¥ï¼Œä½†APIæœ‰æ•ˆ
                    }
                else:
                    error_msg = f"HTTP {response.status_code}: {response.text[:300]}"
                    logger.error(f"   âŒ éªŒè¯å¤±è´¥: {error_msg}")
                    return {
                        "valid": False,
                        "message": f"APIéªŒè¯å¤±è´¥ - {error_msg}",
                        "models": []
                    }
                    
        except httpx.TimeoutException as e:
            error_msg = f"è¯·æ±‚è¶…æ—¶ - å¯èƒ½éœ€è¦é…ç½®ä»£ç†æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥"
            logger.error(f"   âŒ {error_msg}: {str(e)}")
            return {
                "valid": False,
                "message": error_msg,
                "models": []
            }
        except httpx.ConnectError as e:
            error_msg = f"è¿æ¥å¤±è´¥ - æ— æ³•è¿æ¥åˆ° {test_base_url}"
            logger.error(f"   âŒ {error_msg}: {str(e)}")
            return {
                "valid": False,
                "message": f"{error_msg}ã€‚å¦‚æœåœ¨ä¸­å›½å¤§é™†ä½¿ç”¨OpenAIï¼Œå¯èƒ½éœ€è¦é…ç½®ä»£ç†ã€‚",
                "models": []
            }
        except Exception as e:
            error_msg = f"éªŒè¯å¼‚å¸¸: {type(e).__name__} - {str(e)}"
            logger.error(f"   âŒ {error_msg}")
            return {
                "valid": False,
                "message": error_msg,
                "models": []
            }
    
    def get_provider_info(self, provider: str) -> Dict[str, Any]:
        """è·å–æä¾›å•†ä¿¡æ¯"""
        return self.PROVIDERS.get(provider, {})
    
    def list_providers(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰æ”¯æŒçš„æä¾›å•†"""
        return [
            {
                "id": provider_id,
                "name": info["name"],
                "base_url": info["base_url"],
                "default_model": info["default_model"],
                "models": self.available_models.get(provider_id, []),  # ä½¿ç”¨åŠ¨æ€è·å–çš„æ¨¡å‹åˆ—è¡¨
                "configured": provider_id in self.api_keys
            }
            for provider_id, info in self.PROVIDERS.items()
        ]
    
    async def chat_completion(
        self,
        provider: str,
        model: str,
        messages: List[Dict[str, str]],
        stream: bool = False,
        temperature: float = 0.7,
        max_tokens: int = 2000,
        **kwargs
    ) -> Union[Dict[str, Any], Iterator[str]]:
        """
        ç»Ÿä¸€çš„èŠå¤©è¡¥å…¨æ¥å£
        
        Args:
            provider: æä¾›å•†ID
            model: æ¨¡å‹åç§°
            messages: æ¶ˆæ¯åˆ—è¡¨
            stream: æ˜¯å¦æµå¼è¾“å‡º
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
        """
        if provider not in self.PROVIDERS:
            raise ValueError(f"ä¸æ”¯æŒçš„æä¾›å•†: {provider}")
        
        # è·å–é…ç½®
        provider_info = self.PROVIDERS[provider]
        base_url = self.custom_configs.get(provider, {}).get("base_url", provider_info["base_url"])
        api_key = self.api_keys.get(provider, "")
        
        # ç‰¹æ®Šå¤„ç†ä¸åŒæä¾›å•†
        if provider == "gemini":
            return await self._gemini_completion(model, messages, api_key, temperature, max_tokens)
        elif provider == "anthropic":
            return await self._anthropic_completion(model, messages, api_key, stream, temperature, max_tokens)
        else:
            # OpenAIå…¼å®¹æ ¼å¼
            return await self._openai_compatible_completion(
                base_url, api_key, model, messages, stream, temperature, max_tokens
            )
    
    async def _openai_compatible_completion(
        self,
        base_url: str,
        api_key: str,
        model: str,
        messages: List[Dict[str, str]],
        stream: bool,
        temperature: float,
        max_tokens: int
    ) -> Dict[str, Any]:
        """OpenAIå…¼å®¹æ ¼å¼çš„APIè°ƒç”¨"""
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "stream": stream
        }
        
        async with httpx.AsyncClient(timeout=60.0) as client:
            try:
                response = await client.post(
                    f"{base_url}/chat/completions",
                    headers=headers,
                    json=payload
                )
                response.raise_for_status()
                return response.json()
            except Exception as e:
                logger.error(f"APIè°ƒç”¨å¤±è´¥: {e}")
                raise
    
    async def _gemini_completion(
        self,
        model: str,
        messages: List[Dict[str, str]],
        api_key: str,
        temperature: float,
        max_tokens: int
    ) -> Dict[str, Any]:
        """Google Gemini APIè°ƒç”¨"""
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        contents = []
        for msg in messages:
            role = "user" if msg["role"] == "user" else "model"
            contents.append({
                "role": role,
                "parts": [{"text": msg["content"]}]
            })
        
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
        
        payload = {
            "contents": contents,
            "generationConfig": {
                "temperature": temperature,
                "maxOutputTokens": max_tokens
            }
        }
        
        async with httpx.AsyncClient(timeout=60.0) as client:
            try:
                response = await client.post(url, json=payload)
                response.raise_for_status()
                data = response.json()
                
                # è½¬æ¢ä¸ºOpenAIæ ¼å¼
                text = data.get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text", "")
                return {
                    "choices": [{
                        "message": {
                            "role": "assistant",
                            "content": text
                        },
                        "finish_reason": "stop"
                    }],
                    "usage": {
                        "prompt_tokens": 0,
                        "completion_tokens": 0,
                        "total_tokens": 0
                    }
                }
            except Exception as e:
                logger.error(f"Gemini APIè°ƒç”¨å¤±è´¥: {e}")
                raise
    
    async def _anthropic_completion(
        self,
        model: str,
        messages: List[Dict[str, str]],
        api_key: str,
        stream: bool,
        temperature: float,
        max_tokens: int
    ) -> Dict[str, Any]:
        """Anthropic Claude APIè°ƒç”¨"""
        # æå–systemæ¶ˆæ¯
        system = ""
        user_messages = []
        for msg in messages:
            if msg["role"] == "system":
                system = msg["content"]
            else:
                user_messages.append(msg)
        
        headers = {
            "x-api-key": api_key,
            "anthropic-version": "2023-06-01",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": model,
            "messages": user_messages,
            "max_tokens": max_tokens,
            "temperature": temperature
        }
        
        if system:
            payload["system"] = system
        
        async with httpx.AsyncClient(timeout=60.0) as client:
            try:
                response = await client.post(
                    "https://api.anthropic.com/v1/messages",
                    headers=headers,
                    json=payload
                )
                response.raise_for_status()
                data = response.json()
                
                # è½¬æ¢ä¸ºOpenAIæ ¼å¼
                text = data.get("content", [{}])[0].get("text", "")
                return {
                    "choices": [{
                        "message": {
                            "role": "assistant",
                            "content": text
                        },
                        "finish_reason": data.get("stop_reason", "stop")
                    }],
                    "usage": {
                        "prompt_tokens": data.get("usage", {}).get("input_tokens", 0),
                        "completion_tokens": data.get("usage", {}).get("output_tokens", 0),
                        "total_tokens": sum([
                            data.get("usage", {}).get("input_tokens", 0),
                            data.get("usage", {}).get("output_tokens", 0)
                        ])
                    }
                }
            except Exception as e:
                logger.error(f"Claude APIè°ƒç”¨å¤±è´¥: {e}")
                raise


# å…¨å±€å®ä¾‹
multi_model_engine = MultiModelEngine()
